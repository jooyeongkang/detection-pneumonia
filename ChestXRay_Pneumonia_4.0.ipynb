{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ChestXRay_Pneumonia_Final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jooyeongkang/kaggle-chest-x-ray-images-pneumonia/blob/master/ChestXRay_Pneumonia_4.0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWrAZrHqGuK6"
      },
      "source": [
        "# Install & Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkYJZ9BYus-n"
      },
      "source": [
        "! pip install --upgrade pip &> /dev/null\n",
        "! pip install tensorflow &> /dev/null\n",
        "! pip install -q kaggle &> /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zl7agBakAotn",
        "outputId": "3a877d54-af45-47c3-eaf2-2b7eb0be3677"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "##from google.colab import files\n",
        "#uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsqwM6i40gkW"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pathlib\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import f1_score\n",
        "from PIL import Image\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cy4qBf2h1-3V"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e95OBkBJ-1DL"
      },
      "source": [
        "## Jooyeong's Path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeyWqP2e0m0R"
      },
      "source": [
        "# Train Data\n",
        "dir_dt_train = '/content/drive/MyDrive/Data Science/Datasets/chest_xray/train'\n",
        "dir_dt_train = pathlib.Path(dir_dt_train)\n",
        "\n",
        "# Validation Data(merged to the train data due to the small amount of validation data)\n",
        "#dir_dt_val = '/content/drive/MyDrive/Data Science/Datasets/chest_xray/val'\n",
        "#dir_dt_val = pathlib.Path(dir_dt_val)\n",
        "\n",
        "# Test Data\n",
        "dir_dt_test = '/content/drive/MyDrive/Data Science/Datasets/chest_xray/test'\n",
        "dir_dt_test = pathlib.Path(dir_dt_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSYP5WBy2CZU"
      },
      "source": [
        "# Create a dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSwtsRF42QwW"
      },
      "source": [
        "## Define parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_7y2Ini_HJM"
      },
      "source": [
        "batch_size = 32   # Number of Images in each batch\n",
        "img_height = 180  # Size of Height for Resizing\n",
        "img_width = 180   # Size of Width for Resizing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVhlqjIbRyw2"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vorTJ-u7wVQ"
      },
      "source": [
        "### Reference\n",
        "**tf.keras.preprocessing.image_dataset_from_directory**\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PINTarfGsq8"
      },
      "source": [
        "### Subset of Original Data\n",
        "#### Train: 200 images\n",
        "#### Validation: 100 images\n",
        "#### Test: 624 images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXKBvmOJF-B7"
      },
      "source": [
        "dt_train = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    directory=dir_dt_train,\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    class_names=None,\n",
        "    color_mode='grayscale', # Option: rgb\n",
        "    batch_size=batch_size,\n",
        "    image_size=(img_height, img_width),\n",
        "    shuffle=True,\n",
        "    seed=123,\n",
        "    validation_split= 1-(200/5232),\n",
        "    subset='training')\n",
        "\n",
        "# Number of category\n",
        "num_class = len(dt_train.class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01mKwwQu2-sn"
      },
      "source": [
        "dt_val = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    directory=dir_dt_train,\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    class_names=None,\n",
        "    color_mode='grayscale', # Option: rgb\n",
        "    batch_size=batch_size,\n",
        "    image_size=(img_height, img_width),\n",
        "    shuffle=True,\n",
        "    seed=123,\n",
        "    validation_split=100/5232,\n",
        "    subset='validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9rv9QF9lTW2"
      },
      "source": [
        "dt_test = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    directory=dir_dt_test,\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    class_names=None,\n",
        "    color_mode='grayscale', # Option: rgb\n",
        "    batch_size=batch_size,\n",
        "    image_size=(img_height, img_width),\n",
        "    shuffle=True,\n",
        "    seed=123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-XlAarUAGia"
      },
      "source": [
        "## Check Data Structure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSsjEF0p6y55"
      },
      "source": [
        "### Reference\n",
        "**tf.data.Dataset**\n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/data/Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQ75Alfq5Jke"
      },
      "source": [
        "for image_batch, labels_batch in dt_train:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imVEKVbqTmkb"
      },
      "source": [
        "# Visualize Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpbOoFwi4wVY"
      },
      "source": [
        "def visualize_img(dt_aug):\n",
        "\n",
        "  plt.figure(figsize=(10, 10))\n",
        "\n",
        "  if dt_aug != '': # Augmented images\n",
        "    if dt_aug == 'randomflip':\n",
        "      print('RandomFlip Images')\n",
        "      dt_augm_filp = tf.keras.Sequential([layers.experimental.preprocessing.RandomFlip(\"horizontal\")])\n",
        "      for images, labels in dt_train.take(1):\n",
        "        for i in range(9):\n",
        "          augmented_images = dt_augm_filp(images)\n",
        "          ax = plt.subplot(3, 3, i + 1)\n",
        "          plt.imshow(tf.squeeze(augmented_images[i].numpy().astype(\"uint8\")), cmap='gray', vmin=0, vmax=255)\n",
        "          plt.title(dt_train.class_names[labels[i]])\n",
        "          plt.axis(\"off\")\n",
        "          \n",
        "    elif dt_aug == 'randomrotation':\n",
        "      print('RandomRotation Images')\n",
        "      dt_augm_rotation = tf.keras.Sequential([layers.experimental.preprocessing.RandomRotation(0.01)])\n",
        "      for images, labels in dt_train.take(1):\n",
        "        for i in range(9):\n",
        "          augmented_images = dt_augm_rotation(images)\n",
        "          ax = plt.subplot(3, 3, i + 1)\n",
        "          plt.imshow(tf.squeeze(augmented_images[i].numpy().astype(\"uint8\")), cmap='gray', vmin=0, vmax=255)\n",
        "          plt.title(dt_train.class_names[labels[i]])\n",
        "          plt.axis(\"off\")\n",
        "\n",
        "    elif dt_aug == 'randomzoom':\n",
        "      print('RandomZoom Images')\n",
        "      dt_augm_zoom = tf.keras.Sequential([layers.experimental.preprocessing.RandomZoom(0.1)])\n",
        "      for images, labels in dt_train.take(1):\n",
        "        for i in range(9):\n",
        "          augmented_images = dt_augm_zoom(images)\n",
        "          ax = plt.subplot(3, 3, i + 1)\n",
        "          plt.imshow(tf.squeeze(augmented_images[i].numpy().astype(\"uint8\")), cmap='gray', vmin=0, vmax=255)\n",
        "          plt.title(dt_train.class_names[labels[i]])\n",
        "          plt.axis(\"off\")\n",
        "\n",
        "  else: # Original images\n",
        "    print('Original Images')\n",
        "    for images, labels in dt_train.take(1):\n",
        "      for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(tf.squeeze(images[i].numpy().astype(\"uint8\")), cmap='gray', vmin=0, vmax=255)\n",
        "        plt.title(dt_train.class_names[labels[i]])\n",
        "        plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppygoUlrAzjq"
      },
      "source": [
        "## Example of Original Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ib8b0RlKAyPb"
      },
      "source": [
        "visualize_img('')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBSOEusNm-Hi"
      },
      "source": [
        "## Example of Augmented Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wn6uBUMvnJgF"
      },
      "source": [
        "### RandomFlip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MxdEU3llFEI"
      },
      "source": [
        "visualize_img('randomflip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEuhq687nN1G"
      },
      "source": [
        "### RandomRotation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ucD2h7wmszj"
      },
      "source": [
        "visualize_img('randomrotation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeL-qQ6vnShi"
      },
      "source": [
        "### RandomZoom"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CytwBmVsmsnj"
      },
      "source": [
        "visualize_img('randomzoom')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KETI6O-XUJpq"
      },
      "source": [
        "# Configure the dataset for the better performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRAtnpoP7aBp"
      },
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "dt_train = dt_train.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "dt_val = dt_val.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffrGogzuvtvr"
      },
      "source": [
        "# Experimental Designs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1bgCHgdSlxE"
      },
      "source": [
        "## **Define functions to design models**\n",
        "\n",
        "\n",
        "\n",
        "1.   Non-Contrastive Learning\n",
        "  *   Dropout\n",
        "2.   Contrastive Learning\n",
        "  *   Data Augmentation (RandomFlip, RandomRotation, RandomZoom)\n",
        "  *   Dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2XpNhhIA1pg"
      },
      "source": [
        "'''\n",
        "Hyperparameters\n",
        "'''\n",
        "# Number of epochs\n",
        "epochs = 100\n",
        "\n",
        "# Dictionary to store mean accuracies per model\n",
        "mean_accuracies_models = {}\n",
        "\n",
        "def build_model(dt_train, dt_augms):\n",
        "\n",
        "  model = Sequential()\n",
        "  \n",
        "  '''\n",
        "  It is also possible to normalize layer in the building block of the model                   \n",
        "  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
        "  The first convolutional layer can typically have a large kernel, usually with a stride of 2\n",
        "  '''\n",
        "\n",
        "  if dt_augms == []:\n",
        "    print('Non-Contrastive Learning')\n",
        "    model.add(layers.Conv2D(filters=16, kernel_size=5, strides=2, padding='same', activation='relu', input_shape=(img_height, img_width, 1)))\n",
        "  else:\n",
        "    print('Contrastive Learning')\n",
        "    if dt_augms == {'randomflip'}:\n",
        "      print('RandomFlip')\n",
        "      model.add(layers.experimental.preprocessing.RandomFlip(\"horizontal\", seed=123, input_shape=(img_height, img_width, 1)))\n",
        "    elif dt_augms == {'randomrotation'}:\n",
        "      print('RandomRotation')\n",
        "      model.add(layers.experimental.preprocessing.RandomRotation(0.01, seed=123, input_shape=(img_height, img_width, 1)))\n",
        "    elif dt_augms == {'randomzoom'}:\n",
        "      print('RandomZoom')\n",
        "      model.add(layers.experimental.preprocessing.RandomZoom(0.05, seed=123, input_shape=(img_height, img_width, 1)))\n",
        "    elif dt_augms == {'randomflip', 'randomrotation'}:\n",
        "      print('RandomFlip & RandomRotation')\n",
        "      model.add(layers.experimental.preprocessing.RandomFlip(\"horizontal\", seed=123, input_shape=(img_height, img_width, 1)))\n",
        "      model.add(layers.experimental.preprocessing.RandomRotation(0.01, seed=123, input_shape=(img_height, img_width, 1)))\n",
        "    elif dt_augms == {'randomflip', 'randomzoom'}:\n",
        "      print('RandomFlip & RandomZoom')\n",
        "      model.add(layers.experimental.preprocessing.RandomFlip(\"horizontal\", seed=123, input_shape=(img_height, img_width, 1)))\n",
        "      model.add(layers.experimental.preprocessing.RandomZoom(0.05, seed=123, input_shape=(img_height, img_width, 1)))\n",
        "    elif dt_augms == {'randomrotation', 'randomzoom'}:\n",
        "      print('RandomRotation & RandomZoom')\n",
        "      model.add(layers.experimental.preprocessing.RandomRotation(0.01, seed=123, input_shape=(img_height, img_width, 1)))\n",
        "      model.add(layers.experimental.preprocessing.RandomZoom(0.05, seed=123, input_shape=(img_height, img_width, 1)))\n",
        "    elif dt_augms == {'randomflip', 'randomrotation', 'randomzoom'}:\n",
        "      print('RandomFlip & RandomRotation & RandomZoom')\n",
        "      model.add(layers.experimental.preprocessing.RandomFlip(\"horizontal\", seed=123, input_shape=(img_height, img_width, 1)))\n",
        "      model.add(layers.experimental.preprocessing.RandomRotation(0.01, seed=123, input_shape=(img_height, img_width, 1)))\n",
        "      model.add(layers.experimental.preprocessing.RandomZoom(0.05, seed=123, input_shape=(img_height, img_width, 1)))\n",
        "\n",
        "    model.add(layers.Conv2D(filters=16, kernel_size=5, strides=2, padding='same', activation='relu'))\n",
        "       \n",
        "  model.add(layers.MaxPooling2D())\n",
        "  model.add(layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
        "  model.add(layers.MaxPooling2D())\n",
        "  model.add(layers.Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
        "  model.add(layers.MaxPooling2D())\n",
        "  model.add(layers.Conv2D(filters=128, kernel_size=3, padding='same', activation='relu'))\n",
        "  model.add(layers.MaxPooling2D())\n",
        "  model.add(layers.Conv2D(filters=256, kernel_size=3, padding='same', activation='relu'))\n",
        "  model.add(layers.MaxPooling2D())\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(128, activation='relu'))\n",
        "  model.add(layers.Dropout(.3))\n",
        "  model.add(layers.Dense(64, activation='relu'))\n",
        "  model.add(layers.Dropout(.3))\n",
        "  model.add(layers.Dense(num_class, activation='softmax'))\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
        "  \n",
        "  return model\n",
        "\n",
        "\n",
        "def train_model(model):\n",
        "  \n",
        "  # Callback to save the best model\n",
        "  checkpoint_filepath = '/tmp/checkpoint'\n",
        "  model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "      filepath=checkpoint_filepath,\n",
        "      monitor='val_accuracy',\n",
        "      mode='max',\n",
        "      save_best_only=True)\n",
        "\n",
        "  # Train the model\n",
        "  history = model.fit(\n",
        "      x=dt_train,\n",
        "      validation_data=dt_val,\n",
        "      epochs=epochs,\n",
        "      callbacks=[model_checkpoint_callback],\n",
        "      verbose=0)\n",
        "  \n",
        "  return history\n",
        "\n",
        "\n",
        "def plot_evaluation(history):\n",
        "\n",
        "  acc = history.history['accuracy']\n",
        "  val_acc = history.history['val_accuracy']\n",
        "\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  epochs_range = range(len(history.history['val_accuracy']))\n",
        "\n",
        "  plt.figure(figsize=(12, 8))\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "  plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "  plt.legend(loc='lower right')\n",
        "  plt.title('Training and Validation Accuracy')\n",
        "\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.plot(epochs_range, loss, label='Training Loss')\n",
        "  plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "  plt.legend(loc='upper right')\n",
        "  plt.title('Training and Validation Loss')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def test_model(observed_accuracies):\n",
        "  # Load the best model through all epochs from the file path\n",
        "  optimized_model = tf.keras.models.load_model('/tmp/checkpoint')\n",
        "\n",
        "  # Test and evaluate the model\n",
        "  val_score = optimized_model.evaluate(dt_val, batch_size=batch_size, verbose=0)\n",
        "  #print(\"val_score\", val_score[1])\n",
        "  test_score = optimized_model.evaluate(dt_test, batch_size=batch_size, verbose=0)\n",
        "  #print(\"test_score\", test_score[1])\n",
        "\n",
        "  observed_accuracies = np.append(observed_accuracies, test_score[1])\n",
        "  #print(observed_accuracies)\n",
        "  return observed_accuracies"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRLdrXgziX4m"
      },
      "source": [
        "## **Convolutional Neural Network(CNN): Non-Contrastive Learning Approach**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1mwb8p9EGV_"
      },
      "source": [
        "##### Build Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uU6I7o96jhXm"
      },
      "source": [
        "dt_augms = []\n",
        "model_cnn_non_contrastive = build_model(dt_train, dt_augms)\n",
        "model_cnn_non_contrastive.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEMTT1GHEJDH"
      },
      "source": [
        "##### Train & Test & Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXgTL-iYL8Ia"
      },
      "source": [
        "observed_accuracies = np.array([])\n",
        "\n",
        "for i in range(100):\n",
        "\n",
        "  history = train_model(model_cnn_non_contrastive)\n",
        "\n",
        "  if i == 0: # Sample\n",
        "    plot_evaluation(history)\n",
        "\n",
        "  observed_accuracies = test_model(observed_accuracies)\n",
        "\n",
        "mean_accuracies = observed_accuracies.mean()\n",
        "print(\"Mean Accuracies:\", mean_accuracies)\n",
        "mean_accuracies_models['non-constractive'] = mean_accuracies"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjzO8_7Cixuj"
      },
      "source": [
        "## **Convolutional Neural Network(CNN): Contrastive Learning Approach**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0bsV6LuvyoA"
      },
      "source": [
        "### 1.Apply one augmentation:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6xYf3StyEZX"
      },
      "source": [
        "#### 1-1 RandomFlip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XvTu0IKn95F"
      },
      "source": [
        "##### Build Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUv9N2tV0L2i"
      },
      "source": [
        "dt_augms = {'randomflip'}\n",
        "model_cnn_contrastive = build_model(dt_train, dt_augms)\n",
        "model_cnn_contrastive.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3dZ8NuDoBgg"
      },
      "source": [
        "##### Train & Test & Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhfT-7ULKqun"
      },
      "source": [
        "observed_accuracies = np.array([])\n",
        "\n",
        "for i in range(100):\n",
        "\n",
        "  history = train_model(model_cnn_contrastive)\n",
        "\n",
        "  if i == 0: # Sample\n",
        "    plot_evaluation(history)\n",
        "\n",
        "  observed_accuracies = test_model(observed_accuracies)\n",
        "\n",
        "mean_accuracies = observed_accuracies.mean()\n",
        "#print(\"Mean Accuracies:\", mean_accuracies)\n",
        "mean_accuracies_models['constractive-random-flip'] = mean_accuracies"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8jAMwDByJjM"
      },
      "source": [
        "#### 1-2 RandomRotation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqHgcD1ooTDT"
      },
      "source": [
        "##### Build Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gB2Wmapl0NwO"
      },
      "source": [
        "dt_augms = {'randomrotation'}\n",
        "model_cnn_contrastive = build_model(dt_train, dt_augms)\n",
        "model_cnn_contrastive.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAwR9XRnoVWQ"
      },
      "source": [
        "##### Train & Test & Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtlSbbNwLJfB"
      },
      "source": [
        "observed_accuracies = np.array([])\n",
        "\n",
        "for i in range(100):\n",
        "\n",
        "  history = train_model(model_cnn_contrastive)\n",
        "\n",
        "  if i == 0: # Sample\n",
        "    plot_evaluation(history)\n",
        "\n",
        "  observed_accuracies = test_model(observed_accuracies)\n",
        "\n",
        "mean_accuracies = observed_accuracies.mean()\n",
        "print(\"Mean Accuracies:\", mean_accuracies)\n",
        "mean_accuracies_models['constractive-random-rotate'] = mean_accuracies"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZboV8_vyJVJ"
      },
      "source": [
        "#### 1-3 RandomZoom "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGs2yIpiocgv"
      },
      "source": [
        "##### Build Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzlK59Gv0Op6"
      },
      "source": [
        "dt_augms = {'randomzoom'}\n",
        "model_cnn_contrastive = build_model(dt_train, dt_augms)\n",
        "model_cnn_contrastive.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7MKbf66oed2"
      },
      "source": [
        "##### Train & Test & Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXCP3vSWLsWE"
      },
      "source": [
        "observed_accuracies = np.array([])\n",
        "\n",
        "for i in range(100):\n",
        "\n",
        "  history = train_model(model_cnn_contrastive)\n",
        "\n",
        "  if i == 0: # Sample\n",
        "    plot_evaluation(history)\n",
        "\n",
        "  observed_accuracies = test_model(observed_accuracies)\n",
        "\n",
        "mean_accuracies = observed_accuracies.mean()\n",
        "print(\"Mean Accuracies:\", mean_accuracies)\n",
        "mean_accuracies_models['constractive-random-zoom'] = mean_accuracies"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-WR2zOQwXK8"
      },
      "source": [
        "### 2.Apply two augmentations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFROcsTyyU_O"
      },
      "source": [
        "#### 2-1 RandomFlip & RandomRotation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OFNTgr3okJC"
      },
      "source": [
        "##### Build Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rR5eNN4c0Pet"
      },
      "source": [
        "dt_augms = {'randomflip', 'randomrotation'}\n",
        "model_cnn_contrastive = build_model(dt_train, dt_augms)\n",
        "model_cnn_contrastive.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cg4czRf1omZa"
      },
      "source": [
        "##### Train & Test & Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKYAjP6GRSS5"
      },
      "source": [
        "observed_accuracies = np.array([])\n",
        "\n",
        "for i in range(100):\n",
        "\n",
        "  history = train_model(model_cnn_contrastive)\n",
        "\n",
        "  if i == 0: # Sample\n",
        "    plot_evaluation(history)\n",
        "\n",
        "  observed_accuracies = test_model(observed_accuracies)\n",
        "\n",
        "mean_accuracies = observed_accuracies.mean()\n",
        "print(\"Mean Accuracies:\", mean_accuracies)\n",
        "mean_accuracies_models['constractive-random-flip-rotate'] = mean_accuracies"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfXybKS7yU0T"
      },
      "source": [
        "#### 2-2 RandomFlip & RandomZoom"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGv_sWvWosJ8"
      },
      "source": [
        "##### Build Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCJZ7ZmU0QTq"
      },
      "source": [
        "dt_augms = {'randomflip', 'randomzoom'}\n",
        "model_cnn_contrastive = build_model(dt_train, dt_augms)\n",
        "model_cnn_contrastive.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ij4U70_JouWO"
      },
      "source": [
        "##### Train & Test & Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktPB04dqRf_j"
      },
      "source": [
        "observed_accuracies = np.array([])\n",
        "\n",
        "for i in range(100):\n",
        "\n",
        "  history = train_model(model_cnn_contrastive)\n",
        "\n",
        "  if i == 0: # Sample\n",
        "    plot_evaluation(history)\n",
        "\n",
        "  observed_accuracies = test_model(observed_accuracies)\n",
        "\n",
        "mean_accuracies = observed_accuracies.mean()\n",
        "print(\"Mean Accuracies:\", mean_accuracies)\n",
        "mean_accuracies_models['constractive-random-flip-zoom'] = mean_accuracies"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZmoVSaayUHg"
      },
      "source": [
        "#### 2-3 RandomRotation & RotationZoom"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teY9OTjNozuU"
      },
      "source": [
        "##### Build Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSdOWNoU0Ref"
      },
      "source": [
        "dt_augms = {'randomrotation', 'randomzoom'}\n",
        "model_cnn_contrastive = build_model(dt_train, dt_augms)\n",
        "model_cnn_contrastive.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcILSVeHo2YG"
      },
      "source": [
        "##### Train & Test & Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdCfdH4KRrEC"
      },
      "source": [
        "observed_accuracies = np.array([])\n",
        "\n",
        "for i in range(100):\n",
        "\n",
        "  history = train_model(model_cnn_contrastive)\n",
        "\n",
        "  if i == 0: # Sample\n",
        "    plot_evaluation(history)\n",
        "\n",
        "  observed_accuracies = test_model(observed_accuracies)\n",
        "\n",
        "mean_accuracies = observed_accuracies.mean()\n",
        "print(\"Mean Accuracies:\", mean_accuracies)\n",
        "mean_accuracies_models['constractive-random-rotate-zoom'] = mean_accuracies"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAQ875qNwr-J"
      },
      "source": [
        "### 3.Apply all three augmentations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvHQuKRhVtQk"
      },
      "source": [
        "#### 3-1 RandomFlip, RandomRotation & RandomZoom"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4Qeknhbo7eJ"
      },
      "source": [
        "##### Build Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBFQweqY0XU3"
      },
      "source": [
        "dt_augms = {'randomflip', 'randomrotation', 'randomzoom'}\n",
        "model_cnn_contrastive = build_model(dt_train, dt_augms)\n",
        "model_cnn_contrastive.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FR0-nGNUo9uf"
      },
      "source": [
        "##### Train & Test & Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XU2rcj5bRr_t"
      },
      "source": [
        "observed_accuracies = np.array([])\n",
        "\n",
        "for i in range(100):\n",
        "\n",
        "  history = train_model(model_cnn_contrastive)\n",
        "\n",
        "  if i == 0: # Sample\n",
        "    plot_evaluation(history)\n",
        "\n",
        "  observed_accuracies = test_model(observed_accuracies)\n",
        "\n",
        "mean_accuracies = observed_accuracies.mean()\n",
        "print(\"Mean Accuracies:\", mean_accuracies)\n",
        "mean_accuracies_models['constractive-random-flip-rotate-zoom'] = mean_accuracies"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLli-JKbvE04"
      },
      "source": [
        "# Compare Average Accuracies among Models "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8WrPle6fMFo"
      },
      "source": [
        "for model, avg in mean_accuracies_models.items():\n",
        "  print(\"Model: {} | Average accuracy: {}\".format(model, avg))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}